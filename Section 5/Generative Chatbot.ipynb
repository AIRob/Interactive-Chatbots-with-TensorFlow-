{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generative Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Code adapted from https://github.com/tensorflow/nmt#training--how-to-build-our-first-nmt-system\n",
    "\n",
    "Also more insights drawn from https://github.com/thushv89/exercises_thushv_dot_com/blob/master/nmt_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from autocorrect import spell\n",
    "\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "sconfig = tf.ConfigProto()\n",
    "# sconfig.gpu_options.per_process_gpu_memory_fraction = 0.45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 25\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def process_str(string, bot_input=False, bot_output=False):\n",
    "    string = string.strip().lower()\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`:]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = string.split(\" \")\n",
    "    string = [re.sub(r\"[0-9]+\", \"NUM\", token) for token in string]\n",
    "    string = [stemmer.stem(re.sub(r'(.)\\1+', r'\\1\\1', token)) for token in string]\n",
    "    string = [spell(token).lower() for token in string]\n",
    "    # Truncate string\n",
    "    while True:\n",
    "        try:\n",
    "            string.remove(\"\")\n",
    "        except:\n",
    "            break\n",
    "    if(not bot_input and not bot_output):\n",
    "        string = string[0:MAX_LEN]\n",
    "    elif(bot_input):\n",
    "        string = string[0:MAX_LEN-1]\n",
    "        string.insert(0, \"</start>\")\n",
    "    else:\n",
    "        string = string[0:MAX_LEN-1]\n",
    "        string.insert(len(string), \"</end>\")\n",
    "    old_len = len(string)\n",
    "    for i in range((MAX_LEN) - len(string)):\n",
    "        string.append(\" </pad> \")\n",
    "    string = re.sub(\"\\s+\", \" \", \" \".join(string)).strip()\n",
    "    return string, old_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = cPickle.load(open(\"all_convos.pkl\", \"rb\"))\n",
    "print(len(data))\n",
    "user = [item[0] for item in data]\n",
    "bot = [item[1] for item in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if(os.path.isfile(\"user_processed.pkl\")):\n",
    "    user = cPickle.load(open(\"user_processed.pkl\", \"rb\"))\n",
    "else:\n",
    "    user = [process_str(item) for item in user]\n",
    "    cPickle.dump(user, open(\"user_processed.pkl\", \"wb\"))\n",
    "\n",
    "if(os.path.isfile(\"bot_in_processed.pkl\")):\n",
    "    bot_inputs = cPickle.load(open(\"bot_in_processed.pkl\", \"rb\"))\n",
    "else:\n",
    "    bot_inputs = [process_str(item, bot_input=True) for item in bot]\n",
    "    cPickle.dump(bot_inputs, open(\"bot_in_processed.pkl\", \"wb\"))\n",
    "\n",
    "if(os.path.isfile(\"bot_out_processed.pkl\")):\n",
    "    bot_outputs = cPickle.load(open(\"bot_out_processed.pkl\", \"rb\"))\n",
    "else:\n",
    "    bot_outputs = [process_str(item, bot_output=True) for item in bot]\n",
    "    cPickle.dump(bot_outputs, open(\"bot_out_processed.pkl\", \"wb\"))\n",
    "    \n",
    "    \n",
    "user_lens = np.array([message[1] for message in user]).astype(np.int32)\n",
    "user = np.array([message[0] for message in user])\n",
    "\n",
    "bot_inp_lens = np.array([message[1] for message in bot_inputs]).astype(np.int32)\n",
    "bot_out_lens = np.array([message[1] for message in bot_outputs]).astype(np.int32)\n",
    "\n",
    "bot_inputs = np.array([message[0] for message in bot_inputs])\n",
    "bot_outputs = np.array([message[0] for message in bot_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Show statistics about length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Average user message: {}, average bot message: {}\".format(np.mean(user_lens), np.mean(bot_inp_lens)))\n",
    "print(\"80th percentile of user lengths: {}, 80th percentile of bot lengths: {}\".format(np.percentile(user_lens, 80), np.percentile(bot_inp_lens, 80)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Extract vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "\n",
    "bow.fit(user.tolist() + bot_inputs.tolist())\n",
    "vocab = list(bow.vocabulary_.keys())\n",
    "vocab.insert(0, \"NUM\")\n",
    "vocab.insert(0, \"UNK\")\n",
    "vocab.insert(0, \"</end>\")\n",
    "vocab.insert(0, \"</start>\")\n",
    "vocab.insert(0, \"</pad>\")\n",
    "cPickle.dump(vocab, open(\"vocab\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "user_ph = tf.placeholder(user.dtype, name=\"user_placeholder\")\n",
    "bot_inp_ph = tf.placeholder(bot_inputs.dtype, name=\"bot_inp_placeholder\")\n",
    "bot_out_ph = tf.placeholder(bot_outputs.dtype, name=\"bot_out_placeholder\")\n",
    "\n",
    "user_lens_ph = tf.placeholder(user_lens.dtype, shape=[None], name=\"user_len_placeholder\")\n",
    "bot_inp_lens_ph = tf.placeholder(bot_inp_lens.dtype, shape=[None], name=\"bot_inp_lens_placeholder\")\n",
    "bot_out_lens_ph = tf.placeholder(bot_out_lens.dtype, shape=[None], name=\"bot_out_lens_placeholder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf_user = tf.data.Dataset.from_tensor_slices(user_ph)\n",
    "tf_bot_inp = tf.data.Dataset.from_tensor_slices(bot_inp_ph)\n",
    "tf_bot_out = tf.data.Dataset.from_tensor_slices(bot_out_ph)\n",
    "\n",
    "tf_user_lens = tf.data.Dataset.from_tensor_slices(user_lens_ph)\n",
    "tf_bot_inp_lens = tf.data.Dataset.from_tensor_slices(bot_inp_lens_ph)\n",
    "tf_bot_out_lens = tf.data.Dataset.from_tensor_slices(bot_out_lens_ph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data/Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"), tf.name_scope(\"data\"):\n",
    "    words = tf.contrib.lookup.index_table_from_tensor(mapping=tf.constant(vocab), default_value=3)\n",
    "    inverse = tf.contrib.lookup.index_to_string_table_from_tensor(mapping=tf.constant(vocab), default_value=\"UNK\", name=\"inverse_op\")\n",
    "\n",
    "    tf_user = tf_user.map(lambda string: tf.string_split([string])).map(lambda tokens: (words.lookup(tokens)))\n",
    "    tf_bot_inp = tf_bot_inp.map(lambda string: tf.string_split([string])).map(lambda tokens: (words.lookup(tokens)))\n",
    "    tf_bot_out = tf_bot_out.map(lambda string: tf.string_split([string])).map(lambda tokens: (words.lookup(tokens)))\n",
    "    \n",
    "    data = tf.data.Dataset.zip((tf_user, tf_bot_inp, tf_bot_out, tf_user_lens, tf_bot_inp_lens, tf_bot_out_lens))\n",
    "    data = data.shuffle(buffer_size=256).batch(BATCH_SIZE)\n",
    "    data = data.prefetch(10)\n",
    "    data_iterator = tf.data.Iterator.from_structure(data.output_types, data.output_shapes,\n",
    "                                                   None, data.output_classes)\n",
    "    train_init_op = data_iterator.make_initializer(data, name='dataset_init')\n",
    "    user_doc, bot_inp_doc, bot_out_doc, user_len, bot_inp_len, bot_out_len = data_iterator.get_next()\n",
    "    user_doc = tf.sparse_tensor_to_dense(user_doc)\n",
    "    bot_inp_doc = tf.sparse_tensor_to_dense(bot_inp_doc)\n",
    "    bot_out_doc = tf.sparse_tensor_to_dense(bot_out_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"embedding\"):\n",
    "    embedding = tf.get_variable(\"embedding\", [len(vocab), 200], initializer=tf.glorot_uniform_initializer())\n",
    "    \n",
    "    embedded_user = tf.nn.embedding_lookup(embedding, user_doc)\n",
    "    embedded_user_dropout = tf.nn.dropout(embedded_user, 0.7)\n",
    "    \n",
    "    embedded_bot_inp = tf.nn.embedding_lookup(embedding, bot_inp_doc)\n",
    "    embedded_bot_inp_dropout = tf.nn.dropout(embedded_bot_inp, 0.7)\n",
    "    \n",
    "    embedded_user_dropout = tf.reshape(embedded_user_dropout, [-1, MAX_LEN, 200])\n",
    "    embedded_bot_inp_dropout = tf.reshape(embedded_bot_inp_dropout, [-1, MAX_LEN, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"encoder\"):\n",
    "    # Build RNN cell\n",
    "    encoder_GRU = tf.nn.rnn_cell.GRUCell(128)\n",
    "    encoder_cell_fw = tf.nn.rnn_cell.DropoutWrapper(encoder_GRU, input_keep_prob=0.7, \n",
    "                                                 output_keep_prob=0.7, state_keep_prob=0.9)\n",
    "    \n",
    "    encoder_cell_bw = tf.nn.rnn_cell.DropoutWrapper(encoder_GRU, input_keep_prob=0.7, \n",
    "                                                 output_keep_prob=0.7, state_keep_prob=0.9)\n",
    "    encoder_outputs, encoder_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "        encoder_cell_fw, encoder_cell_bw, embedded_user_dropout,\n",
    "        sequence_length=user_len, dtype=tf.float32)\n",
    "    encoder_state = tf.concat(encoder_state, -1)\n",
    "    encoder_outputs = tf.concat(encoder_outputs, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "attention_mechanism = tf.contrib.seq2seq.LuongAttention(256, encoder_outputs,\n",
    "    memory_sequence_length=user_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Projection layer (Output of decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"projection\"):\n",
    "    projection_layer = tf.layers.Dense(\n",
    "    len(vocab), use_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"decoder\"):\n",
    "    decoder_GRU = tf.nn.rnn_cell.GRUCell(256)\n",
    "    decoder_cell = tf.nn.rnn_cell.DropoutWrapper(decoder_GRU, input_keep_prob=0.7, \n",
    "                                                 output_keep_prob=0.7, state_keep_prob=0.9)\n",
    "    decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism,\n",
    "                                                       attention_layer_size=128)\n",
    "    \n",
    "    decoder_initial_state = decoder_cell.zero_state(BATCH_SIZE, tf.float32).clone(\n",
    "                                cell_state=encoder_state)\n",
    "    # Helper for use during training\n",
    "    # During training we feed the decoder\n",
    "    # the target sequence\n",
    "    # However, during testing we use the decoder's\n",
    "    # last output\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "        embedded_bot_inp_dropout, bot_inp_len)\n",
    "    # Decoder\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        decoder_cell, helper, decoder_initial_state,\n",
    "        output_layer=projection_layer)\n",
    "    # Dynamic decoding\n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "    logits = outputs.rnn_output\n",
    "    translations = outputs.sample_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loss computation normalized by batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.reshape(bot_out_doc,\n",
    "                                                                    [-1, MAX_LEN]), logits=logits)\n",
    "    mask = tf.sequence_mask(bot_out_len, dtype=tf.float32)\n",
    "    train_loss = (tf.reduce_sum(loss * mask) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Adam with gradient clipping and learning rate scheduling using cosine decay + restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('Adam'):\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    inc_gstep = tf.assign(global_step,global_step + 1)\n",
    "    learning_rate = tf.train.cosine_decay_restarts(0.001, global_step, 550, t_mul=1.1)\n",
    "    adam_optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    adam_gradients, v = zip(*adam_optimizer.compute_gradients(train_loss))\n",
    "    adam_gradients, _ = tf.clip_by_global_norm(adam_gradients, 10.0)\n",
    "    adam_optimize = adam_optimizer.apply_gradients(zip(adam_gradients, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Inference nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"inference\"):\n",
    "    # Helper\n",
    "    # Start token is 1, which is the </start> token\n",
    "    # End token is 2\n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "        embedding,\n",
    "        tf.fill([BATCH_SIZE], 1), 2)\n",
    "\n",
    "    # Decoder\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        decoder_cell, helper, decoder_initial_state,\n",
    "        output_layer=projection_layer)\n",
    "    # Dynamic decoding\n",
    "    test_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "        decoder, maximum_iterations=10)\n",
    "    test_translations = tf.identity(test_outputs.sample_id, name=\"word_ids\")\n",
    "    test_words = tf.identity(inverse.lookup(tf.cast(test_translations, tf.int64)), name=\"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## A function for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def testBot(sess):\n",
    "    text = [\"Hello\"] + [\"\"] * (BATCH_SIZE - 1)\n",
    "    num_text = len(text)\n",
    "    text = [process_str(sentence) for sentence in text]\n",
    "    text_len = np.array([item[1] for item in text]).astype(np.int32)\n",
    "    text = np.array([item[0] for item in text])\n",
    "    \n",
    "    user_test_ph = tf.placeholder(text.dtype)\n",
    "    user_test_lens_ph = tf.placeholder(text_len.dtype)\n",
    "    \n",
    "    tf_user_test = tf.data.Dataset.from_tensor_slices(user_test_ph).map(lambda string: tf.string_split([string])).map(lambda tokens: (words.lookup(tokens)))\n",
    "    tf_user_test_lens = tf.data.Dataset.from_tensor_slices(user_test_lens_ph)\n",
    "    \n",
    "    test_data = tf.data.Dataset.zip((tf_user_test, tf_bot_inp, tf_bot_out,\n",
    "                                     tf_user_test_lens, tf_bot_inp_lens, tf_bot_out_lens))\n",
    "    \n",
    "    test_data = test_data.batch(num_text).prefetch(1)\n",
    "    test_init_op = data_iterator.make_initializer(test_data)\n",
    "    \n",
    "    sess.run(test_init_op, feed_dict={\n",
    "        user_test_ph: user,\n",
    "        bot_inp_ph: bot_inputs[0:num_text],\n",
    "        bot_out_ph: bot_outputs[0:num_text],\n",
    "        user_test_lens_ph: user_lens,\n",
    "        bot_inp_lens_ph: bot_inp_lens[0:num_text],\n",
    "        bot_out_lens_ph: bot_out_lens[0:num_text]\n",
    "    })\n",
    "    translations_text = sess.run(inverse.lookup(tf.cast(test_translations, tf.int64)))\n",
    "    return translations_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('Loss', train_loss)\n",
    "    tf.summary.scalar('LR', learning_rate)\n",
    "    merged = tf.summary.merge_all()\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding_vis = config.embeddings.add()\n",
    "    embedding_vis.tensor_name = embedding.name\n",
    "    vocab_str = '\\n'.join(vocab)\n",
    "    metadata = pd.Series(vocab)\n",
    "    metadata.name = \"label\"\n",
    "    metadata.to_csv(\"checkpoints/metadata.tsv\", sep=\"\\t\", header=True, index_label=\"index\")\n",
    "    embedding_vis.metadata_path = 'metadata.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "print(\"Started training\")\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "save_dir = 'checkpoints/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_path = os.path.join(save_dir, 'best_validation')\n",
    "\n",
    "sess = tf.InteractiveSession(config=sconfig)\n",
    "\n",
    "writer = tf.summary.FileWriter('./checkpoints', sess.graph)\n",
    "projector.visualize_embeddings(writer, config)\n",
    "\n",
    "\n",
    "sess.run([words.init, tf.global_variables_initializer(), inverse.init])\n",
    "step = 0\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    if(i % 10 == 0):\n",
    "        saver.save(sess=sess, save_path=save_path, write_meta_graph=True)\n",
    "    sess.run(train_init_op, feed_dict={\n",
    "        user_ph: user,\n",
    "        bot_inp_ph: bot_inputs,\n",
    "        bot_out_ph: bot_outputs,\n",
    "        user_lens_ph: user_lens,\n",
    "        bot_inp_lens_ph: bot_inp_lens,\n",
    "        bot_out_lens_ph: bot_out_lens\n",
    "    })\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            _, batch_loss, summary = sess.run([adam_optimize, train_loss, merged])\n",
    "            writer.add_summary(summary, i)\n",
    "            losses.append(batch_loss)\n",
    "        except tf.errors.InvalidArgumentError:\n",
    "            continue\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"Epoch {}: Loss(Mean): {} Loss(Std): {}\".format(i, np.mean(losses), np.std(losses)))\n",
    "            losses = []\n",
    "            break\n",
    "        sess.run(inc_gstep)\n",
    "        step += 1\n",
    "    print(testBot(sess)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
